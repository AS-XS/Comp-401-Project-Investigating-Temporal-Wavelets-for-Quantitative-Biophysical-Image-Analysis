{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d150a43-a2bf-459d-98fa-1a3fa4c7433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2d2a6e-4e80-4202-8e70-08344fff5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e643227b-acfa-4101-89a0-dbe40e45d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "grid_size_x = 100  # size of the x\n",
    "grid_size_y = 100   # size of the y\n",
    "space_size = 100 # physical space size\n",
    "num_emitters = 100  # number of point emitters (proteins)\n",
    "timesteps = 50  # number of time steps for diffusion simulation\n",
    "resolution = 100  # resolution of the continuous space for better smoothing\n",
    "prefactor = np.sqrt(2)  # prefactor for Brownian motion in 2D\n",
    "diffusion_coefficient = 1.0  # diffusion coefficient (D) in µm^2/s\n",
    "time_step = 1.0  # time step (dt) in seconds\n",
    "psf_sigma = 1.0  # standard deviation for the Gaussian PSF\n",
    "noise_sigma = 0.05  # standard deviation for Gaussian noise\n",
    "brightness_factor = 1000 # Adjust this factor as needed to simulate realistic photon counts\n",
    "molecule_magnitude = 10  # Define the magnitude of each molecule\n",
    "\n",
    "# Define the mesh confinement boundary\n",
    "confine_x_min, confine_x_max = -(grid_size_x + (0.1*grid_size_x)), (grid_size_x + (0.1*grid_size_x))  # x-axis confinement boundaries\n",
    "confine_y_min, confine_y_max = -(grid_size_y + (0.1*grid_size_y)), (grid_size_y + (0.1*grid_size_y))  # y-axis confinement boundaries\n",
    "\n",
    "# Mesh parameters within general confinement region\n",
    "mesh_width = confine_x_max - confine_x_min\n",
    "mesh_height = confine_y_max - confine_y_min\n",
    "\n",
    "#graphing area\n",
    "graph_x_min = 0\n",
    "graph_x_max = space_size  \n",
    "graph_y_min = 0\n",
    "graph_y_max = space_size\n",
    "\n",
    "# Define the skeletal meshwork (e.g., 4x4 grid of confinement zones)\n",
    "num_boxes = 10  # Number of confinement boxes along each axis\n",
    "box_size_x = mesh_width / num_boxes\n",
    "box_size_y = mesh_height / num_boxes\n",
    "hop_probability = 0.1  # Probability of hopping to a neighboring box\n",
    "\n",
    "# create a 2D grid to represent the point emitters\n",
    "grid = np.zeros((grid_size_x, grid_size_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc07f34-3fcc-42b7-a687-cbde5814a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random positions for the point emitters inside the grid\n",
    "emitters = np.random.uniform(0, space_size, (num_emitters, 2))\n",
    "\n",
    "# Initialize trajectories for each molecule\n",
    "trajectories = [[] for _ in range(num_emitters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3650bb6-a523-44c1-ba59-063a00e83c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffuse_with_mesh_and_global_confinement(emitters, space_size, prefactor, diffusion_coefficient, time_step, num_boxes, box_size_x, box_size_y, hop_probability, confine_x_min, confine_x_max, confine_y_min, confine_y_max):\n",
    "    new_emitters = []\n",
    "    for emitter in emitters:\n",
    "        current_x, current_y = emitter\n",
    "\n",
    "        # Diffuse molecule (Brownian motion step)\n",
    "        step_scale = prefactor * np.sqrt(diffusion_coefficient * time_step)\n",
    "        dx, dy = np.random.normal(0, step_scale, 2)\n",
    "        new_x = current_x + dx\n",
    "        new_y = current_y + dy\n",
    "\n",
    "        # Wrap around at global boundaries (toroidal space)\n",
    "        if new_x < confine_x_min:\n",
    "            new_x = confine_x_max - (confine_x_min - new_x)\n",
    "        elif new_x > confine_x_max:\n",
    "            new_x = confine_x_min + (new_x - confine_x_max)\n",
    "\n",
    "        if new_y < confine_y_min:\n",
    "            new_y = confine_y_max - (confine_y_min - new_y)\n",
    "        elif new_y > confine_y_max:\n",
    "            new_y = confine_y_min + (new_y - confine_y_max)\n",
    "\n",
    "        # Determine the current box bounds\n",
    "        box_start_x = (current_x // box_size_x) * box_size_x\n",
    "        box_start_y = (current_y // box_size_y) * box_size_y\n",
    "        box_end_x = box_start_x + box_size_x\n",
    "        box_end_y = box_start_y + box_size_y\n",
    "\n",
    "        # Check if the molecule tries to escape the current box\n",
    "        if np.random.uniform(0, 1) < hop_probability:\n",
    "            # Allow hopping into a neighboring box within global boundaries\n",
    "            if new_x < box_start_x:\n",
    "                new_x = max(new_x, box_start_x - box_size_x)\n",
    "            elif new_x > box_end_x:\n",
    "                new_x = min(new_x, box_end_x + box_size_x)\n",
    "\n",
    "            if new_y < box_start_y:\n",
    "                new_y = max(new_y, box_start_y - box_size_y)\n",
    "            elif new_y > box_end_y:\n",
    "                new_y = min(new_y, box_end_y + box_size_y)\n",
    "        else:\n",
    "            # Constrain the molecule within its current box\n",
    "            new_x = np.clip(new_x, box_start_x, box_end_x)\n",
    "            new_y = np.clip(new_y, box_start_y, box_end_y)\n",
    "\n",
    "        # Append updated position\n",
    "        new_emitters.append([new_x, new_y])\n",
    "\n",
    "    return np.array(new_emitters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1c834-d948-41b6-837c-87a5c86da93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rickerWavelet(t,a,b):\n",
    "    t = (t-b)/a\n",
    "    return (1/np.sqrt(a))*(1-t**2)*np.exp((-1/2)*(t**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8a204-bdf0-4a7c-ba20-0f34624c0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveletTransform(ts, signal, a):\n",
    "    center = ts[len(ts) // 2]  \n",
    "    kernel = rickerWavelet(ts, a, center)\n",
    "    kernel = np.fft.fftshift(kernel)\n",
    "\n",
    "    kernel_length = signal.shape[-1]\n",
    "    if len(kernel) < kernel_length:\n",
    "        padding = (kernel_length - len(kernel)) // 2\n",
    "        kernel = np.pad(kernel, (padding, kernel_length - len(kernel) - padding), mode='constant')\n",
    "    elif len(kernel) > kernel_length:\n",
    "        excess = (len(kernel) - kernel_length) // 2\n",
    "        kernel = kernel[excess:excess + kernel_length]\n",
    "\n",
    "    convolution = np.fft.irfft(np.fft.rfft(signal) * np.conj(np.fft.rfft(kernel, n=signal.shape[-1])))\n",
    "    return convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e4b31-6759-464d-93f7-ae696bd24903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverseWaveletTransform(ts, waveletCoefficients, scale, Cg=np.pi):\n",
    "    center = ts[-1]/2\n",
    "    signal = np.zeros(len(waveletCoefficients))  \n",
    "\n",
    "    kernel = rickerWavelet(ts, scale, center)  \n",
    "    kernel = np.fft.fftshift(kernel)\n",
    "    signal += (1 / scale**2) * np.fft.irfft(np.fft.rfft(kernel) * np.fft.rfft(waveletCoefficients))\n",
    "\n",
    "    return (1 / Cg) * signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcacf986-9a3d-4e83-a35b-f29696cca7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the Mean Squared Error between the original and reconstructed signal\n",
    "def compute_error(original_signal, reconstructed_signal):\n",
    "    return np.mean((original_signal - reconstructed_signal) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee9f57-767d-4107-a676-3e628ede25b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the best wavelet scale\n",
    "def find_best_wavelet_scale(ts, signal, scales):\n",
    "    best_scale = None\n",
    "    min_error = float('inf')\n",
    "    best_reconstructed_signal = None\n",
    "\n",
    "    # Try different scales\n",
    "    for scale in scales:\n",
    "        # Apply wavelet transform\n",
    "        transformed_signal = waveletTransform(ts, signal, scale)\n",
    "        \n",
    "        # Inverse wavelet transform to reconstruct the signal\n",
    "        reconstructed_signal = inverseWaveletTransform(ts, transformed_signal, scale)\n",
    "        \n",
    "        # Compute the error between the original and reconstructed signals\n",
    "        error = compute_error(signal, reconstructed_signal)\n",
    "        \n",
    "        # Update best scale if a lower error is found\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            best_scale = scale\n",
    "            best_reconstructed_signal = reconstructed_signal\n",
    "\n",
    "    return best_scale, best_reconstructed_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc69b1-1582-47aa-8beb-add9ec9b44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the autocorrelation of a signal\n",
    "def autoCorrelation(data):\n",
    "    # Nearest size with power of 2\n",
    "    size = 2 ** np.ceil(np.log2(2 * len(data) - 1)).astype(int)\n",
    "\n",
    "    # Variance\n",
    "    var = np.var(data)\n",
    "\n",
    "    # Normalized data\n",
    "    ndata = data - np.mean(data)\n",
    "\n",
    "    # Compute the FFT\n",
    "    fft = np.fft.fft(ndata, size)\n",
    "\n",
    "    # Get the power spectrum\n",
    "    pwr = np.abs(fft) ** 2\n",
    "\n",
    "    # Calculate the autocorrelation from inverse FFT of the power spectrum\n",
    "    acorr = np.fft.ifft(pwr).real / var / len(data)\n",
    "\n",
    "    # Truncate to the original size\n",
    "    acorr = acorr[:len(data)]\n",
    "\n",
    "    return acorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ab0c7-1c2c-47dc-930b-be74ddf9e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperbolic decay model\n",
    "def hyperbolic_decay(tau, a, td):\n",
    "    return a / (tau / td + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d585669c-3b1e-49c1-b2d3-6a15ed2b259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_autocorrelation_to_decay_exclude_zero(acorr, xs, beam_radius):\n",
    "    # Exclude tau = 0 (first data point)\n",
    "    acorr_no_zero = acorr[1:]\n",
    "    xs_no_zero = xs[1:]\n",
    "    \n",
    "    # Fit the hyperbolic decay model\n",
    "    popt, pcov = curve_fit(hyperbolic_decay, xs_no_zero, acorr_no_zero, p0=[1.0, 1.0])\n",
    "    a_fit, td_fit = popt\n",
    "    \n",
    "    # Calculate diffusion coefficient D\n",
    "    D = beam_radius**2 / (4 * td_fit)\n",
    "    \n",
    "    # Generate the fitted autocorrelation curve\n",
    "    fitted_acorr = hyperbolic_decay(xs, a_fit, td_fit)\n",
    "    \n",
    "    return a_fit, td_fit, D, fitted_acorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d20bb-c1ec-421b-9bc2-240110bcfaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lags(signal_length):\n",
    "    return np.arange(1, signal_length + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de739861-627f-4a4d-a754-e985504c5185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoCorrelation_exclude_zero(data):\n",
    "    size = 2 ** np.ceil(np.log2(2 * len(data) - 1)).astype(int)\n",
    "    var = np.var(data)\n",
    "    ndata = data - np.mean(data)\n",
    "    fft = np.fft.fft(ndata, size)\n",
    "    pwr = np.abs(fft) ** 2\n",
    "    acorr = np.fft.ifft(pwr).real / var / len(data)\n",
    "    return acorr[1:]  # Exclude τ=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dfdf8f-42bb-4044-8d26-2896f53ed4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_autocorrelation(acorr, lags, beam_radius):\n",
    "    truncated_lags = lags[:len(acorr)]  \n",
    "    truncated_acorr = acorr\n",
    "\n",
    "    initial_a = np.max(truncated_acorr)  \n",
    "    initial_td = np.mean(truncated_lags) / 2  \n",
    "    p0 = [initial_a, initial_td]\n",
    "\n",
    "    popt, _ = curve_fit(hyperbolic_decay, truncated_lags, truncated_acorr, p0=p0, maxfev=2000)\n",
    "    a_fit, td_fit = popt\n",
    "\n",
    "    D = beam_radius**2 / (4 * td_fit)\n",
    "\n",
    "    return a_fit, td_fit, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8166fd09-be15-4872-90ba-4b0ad81349bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time evolution simulation with mesh confinement\n",
    "returnedArray = []\n",
    "for t in range(timesteps):\n",
    "    # diffuse emitters with confinement\n",
    "    emitters = diffuse_with_mesh_and_global_confinement(emitters, space_size, prefactor, diffusion_coefficient, time_step, num_boxes, box_size_x, box_size_y, hop_probability,confine_x_min, confine_x_max, confine_y_min, confine_y_max)\n",
    "\n",
    "    # Count how many molecules are inside the graphed area\n",
    "    inside_graph = np.sum(\n",
    "        (emitters[:, 0] >= graph_x_min) & (emitters[:, 0] <= graph_x_max) &\n",
    "        (emitters[:, 1] >= graph_y_min) & (emitters[:, 1] <= graph_y_max)\n",
    "    )\n",
    "\n",
    "    # Print or store the count for each timestep\n",
    "    print(f\"Timestep {t+1}: {inside_graph} molecules inside the graphed area.\")\n",
    "    \n",
    "    # create a high-resolution blank space for emitters\n",
    "    high_res_space = np.zeros((resolution, resolution))\n",
    "    high_res_space *= brightness_factor\n",
    "    \n",
    "    for i, emitter in enumerate(emitters):\n",
    "        # Map continuous emitter positions to high-resolution grid\n",
    "        x = int(emitter[0] * (resolution / space_size))\n",
    "        y = int(emitter[1] * (resolution / space_size))\n",
    "\n",
    "        # Clip the indices to ensure they are within bounds\n",
    "        x = np.clip(x, 0, resolution - 1)\n",
    "        y = np.clip(y, 0, resolution - 1)\n",
    "\n",
    "        high_res_space[x, y] += molecule_magnitude\n",
    "        trajectories[i].append(emitter)  # Append current position to trajectory\n",
    "\n",
    "    # Convolve with Gaussian PSF, add noise, and visualize\n",
    "    simulated_image = gaussian_filter(high_res_space, sigma=psf_sigma)\n",
    "    noise = np.random.normal(0, noise_sigma, simulated_image.shape)\n",
    "    noised_image = simulated_image + noise\n",
    "    noised_image = np.abs(noised_image)\n",
    "    returnedArray.append(noised_image)\n",
    "\n",
    "    # create a figure with scatter plot and PSF-blurred scatter for comparison\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # plot scatter plot of emitters in continuous space (left)\n",
    "    axes[0].scatter(emitters[:, 1], emitters[:, 0], c='blue', s=100, alpha=0.8, label=\"Emitters\")\n",
    "    axes[0].set_xlim(0, space_size)\n",
    "    axes[0].set_ylim(0, space_size)\n",
    "    axes[0].invert_yaxis()  # Invert y-axis for correct orientation\n",
    "    axes[0].set_title(f\"Protein Positions with Confinement - Timestep {t + 1}\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # plot the PSF-blurred image with added Gaussian noise (mid)\n",
    "    im = axes[1].imshow(noised_image, cmap='PiYG', interpolation='bilinear', extent=(0, space_size, 0, space_size))\n",
    "    axes[1].set_title(f\"Simulated Image with Gaussian Noise - Timestep {t + 1}\")\n",
    "    plt.colorbar(im, ax=axes[1], label='Intensity')\n",
    "\n",
    "    # Plot Mesh simulation (right)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, num_emitters))\n",
    "    # Plot the skeletal meshwork\n",
    "    for i in range(1, num_boxes):\n",
    "        # Vertical lines\n",
    "        axes[2].axvline(confine_x_min + i * box_size_x, color='yellow', linestyle='--', linewidth=1)\n",
    "        # Horizontal lines\n",
    "        axes[2].axhline(confine_y_min + i * box_size_y, color='yellow', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Plot trajectories\n",
    "    for i, trajectory in enumerate(trajectories):\n",
    "        traj_x = [pos[0] for pos in trajectory]\n",
    "        traj_y = [pos[1] for pos in trajectory]\n",
    "        axes[2].plot(traj_x, traj_y, color=colors[i], linewidth=1, label=f'Molecule {i+1}' if t == timesteps - 1 else \"\")\n",
    "\n",
    "    # Plot emitter positions within the meshwork\n",
    "    axes[2].scatter(emitters[:, 1], emitters[:, 0], c=[colors[i]], s=50)\n",
    "    axes[2].set_xlim(0, space_size)\n",
    "    axes[2].set_ylim(0, space_size)\n",
    "    axes[2].invert_yaxis()\n",
    "    axes[2].set_title(f\"Skeletal Meshwork Simulation- Timestep {t + 1}\")\n",
    "    axes[2].grid(False)\n",
    "\n",
    "    # Add global confinement boundaries to the mesh plot\n",
    "    axes[2].axvline(confine_x_min, color='red', linestyle='--', linewidth=1, label='Global Boundary')\n",
    "    axes[2].axvline(confine_x_max, color='red', linestyle='--', linewidth=1)\n",
    "    axes[2].axhline(confine_y_min, color='red', linestyle='--', linewidth=1)\n",
    "    axes[2].axhline(confine_y_max, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Set the background color of the mesh graph\n",
    "    axes[2].set_facecolor('darkblue')\n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46b276-7dbe-45cc-abb3-682520800445",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(returnedArray[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fce04b-4163-4ffb-a33d-4f7b95c94296",
   "metadata": {},
   "outputs": [],
   "source": [
    "transposedArray = np.transpose(returnedArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d14483-0ec9-41e2-a605-626625508d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(transposedArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2478f423-fd0a-429b-8fd0-f75b0d4e9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(transposedArray[50,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57532fa6-c811-4adc-a6a2-1ff72d4d179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range of possible scales\n",
    "scale_min = 1  # Minimum scale value\n",
    "scale_max = 10  # Maximum scale value\n",
    "scale_step = 0.1  # Step size for scale range\n",
    "\n",
    "# Generate scale values to explore\n",
    "scales = np.arange(scale_min, scale_max, scale_step)\n",
    "xs = np.linspace(0, timesteps * time_step, timesteps)\n",
    "signal = transposedArray[50, :]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb696966-c964-4039-8cd6-305aed3e4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = []\n",
    "\n",
    "# Apply wavelet transform to each row\n",
    "for i in range(signal.shape[0]):  \n",
    "    row_signal = signal[i, :]\n",
    "    row_transform = []\n",
    "    for scale in scales:\n",
    "        transformed_row_signal = waveletTransform(xs, row_signal, scale)\n",
    "        row_transform.append(transformed_row_signal)\n",
    "    \n",
    "    transform.append(np.array(row_transform))\n",
    "\n",
    "# Convert the list to a numpy array \n",
    "transform = np.array(transform)\n",
    "\n",
    "# Initialize the array for the inverse transform\n",
    "inverseTransformSignal = np.zeros_like(signal)\n",
    "\n",
    "for i in range(signal.shape[0]):  # Loop over each row of the signal\n",
    "    row_transform = transform[i, :, :]  # Get the transformed coefficients for this row\n",
    "\n",
    "    # Inverse transform for each scale\n",
    "    for scale_idx in range(len(scales)):\n",
    "        # Ensure you are passing a 1D wavelet coefficient for each scale\n",
    "        inverse_signal = inverseWaveletTransform(xs, row_transform[scale_idx], scales[scale_idx])\n",
    "        \n",
    "        # Store the result in the inverseTransformSignal for the current row\n",
    "        inverseTransformSignal[i, :] = inverse_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2339a2a4-21d3-48eb-98ee-cc52212067ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays to store best scales and reconstructed signals\n",
    "best_scales = []\n",
    "reconstructed_signals = []\n",
    "\n",
    "# Loop through each row in the signal\n",
    "for i in range(signal.shape[0]):  \n",
    "    row_signal = signal[i, :]  \n",
    "    \n",
    "    # Find the best scale and corresponding reconstructed signal for this row\n",
    "    best_scale, best_reconstructed_signal = find_best_wavelet_scale(xs, row_signal, scales)\n",
    "    \n",
    "    # Store the results\n",
    "    best_scales.append(best_scale)\n",
    "    reconstructed_signals.append(best_reconstructed_signal)\n",
    "\n",
    "# Convert reconstructed signals to a 2D array\n",
    "reconstructed_signals = np.array(reconstructed_signals)\n",
    "\n",
    "# Display results\n",
    "print(\"Best scales for each row:\", best_scales)\n",
    "\n",
    "# Plot the original and reconstructed signal for comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(signal, aspect='auto', cmap='viridis')\n",
    "plt.title(\"Original Signal\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(reconstructed_signals, aspect='auto', cmap='viridis')\n",
    "plt.title(\"Reconstructed Signal\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b6368f-3ca9-4427-ace6-2321d0914593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select row 50 of the signal (index 49 since indexing starts from 0)\n",
    "row_50_signal = signal[49, :]  # Extract row 50\n",
    "\n",
    "# Find the best wavelet scale for this row\n",
    "best_scale, best_reconstructed_signal = find_best_wavelet_scale(xs, row_50_signal, scales)\n",
    "\n",
    "# Compute the autocorrelation of the original and reconstructed signals\n",
    "original_acorr = autoCorrelation(row_50_signal)\n",
    "reconstructed_acorr = autoCorrelation(best_reconstructed_signal)\n",
    "\n",
    "# Print the best scale\n",
    "print(\"Best scale for row 50:\", best_scale)\n",
    "\n",
    "# Plot the original and reconstructed signals\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Original vs reconstructed signal\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(xs, row_50_signal, label='Original Signal (Row 50)', alpha=0.7)\n",
    "plt.plot(xs, best_reconstructed_signal, label=f'Reconstructed Signal (Best Scale: {best_scale})', linestyle='--')\n",
    "plt.title(\"Wavelet Transform and Reconstruction for Row 50\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Signal Amplitude\")\n",
    "plt.legend()\n",
    "\n",
    "# Autocorrelation comparison\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(original_acorr, label='Original Signal Autocorrelation', alpha=0.7)\n",
    "plt.plot(reconstructed_acorr, label='Reconstructed Signal Autocorrelation', linestyle='--')\n",
    "plt.title(\"Autocorrelation of Original and Reconstructed Signal (Row 50)\")\n",
    "plt.xlabel(\"Lag\")\n",
    "plt.ylabel(\"Autocorrelation\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fc09cd-b7eb-49a3-b672-3c74c33642c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for simulations\n",
    "beam_radius = 0.5 \n",
    "simulated_D_values = []\n",
    "# Number of simulations\n",
    "num_simulations = 10 \n",
    "diffusion_coefficient = 2.5\n",
    "row_signal = simulated_image[row_index, :] \n",
    "acorr = autoCorrelation_exclude_zero(row_signal) \n",
    "lags = np.arange(1, len(acorr) + 1)  \n",
    "row_index = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d4c183-5ea2-4727-aeab-89872d2dc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_fit, td_fit, fitted_acorr = fit_autocorrelation_to_decay(original_acorr, xs, beam_radius, diffusion_coefficient)\n",
    "\n",
    "# Print the best-fit parameters\n",
    "print(f\"Best-fit a: {a_fit}\")\n",
    "print(f\"Best-fit td: {td_fit}\")\n",
    "\n",
    "# Plot the autocorrelation and the fitted curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(xs, original_acorr, label='Original Signal Autocorrelation', alpha=0.7)\n",
    "plt.plot(xs, fitted_acorr, label=f'Fitted Hyperbolic Decay (a={a_fit:.2f}, td={td_fit:.2f})', linestyle='--')\n",
    "plt.title(\"Autocorrelation Fitting to Hyperbolic Decay\")\n",
    "plt.xlabel(\"Lag (τ)\")\n",
    "plt.ylabel(\"Autocorrelation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1fd1f0-f38e-4ffe-af6f-c1457d1a7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_fit, td_fit, D = fit_autocorrelation(acorr, lags, beam_radius)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Fitted parameters:\")\n",
    "print(f\"  a = {a_fit:.3f}\")\n",
    "print(f\"  td = {td_fit:.3f}\")\n",
    "print(f\"  D = {D:.3f} µm²/s\")\n",
    "\n",
    "# Plot the results for validation\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(lags, acorr, label='Autocorrelation (τ > 0)')\n",
    "plt.plot(\n",
    "    lags,\n",
    "    [a_fit / (tau / td_fit + 1) for tau in lags],\n",
    "    linestyle='--',\n",
    "    label=f'Fitted Decay (D={D:.3f})'\n",
    ")\n",
    "plt.title(\"Autocorrelation and Fitted Model\")\n",
    "plt.xlabel(\"Lag (τ)\")\n",
    "plt.ylabel(\"Autocorrelation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
